{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cab\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score,precision_recall_fscore_support,roc_curve,auc,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import gc\n",
    "#from featexp import get_univariate_plots#用于特征筛选，需要先安装featexp\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams['font.sans-serif']=['Simhei']\n",
    "plt.rcParams['axes.unicode_minus']=False\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "base_info shape: (24865, 33) id unique: 24865\nannual_report_info shape: (22550, 23) id unique: 8937\ntax_info shape: (29195, 9) id unique: 808\nchange_info shape: (29195, 9) id unique: 808\nnews_info shape: (10518, 3) id unique: 927\nother_info shape: (1890, 4) id unique: 1888\nentprise_info shape: (14865, 2) id unique: 14865\nentprise_evaluate shape: (10000, 2) id unique: 10000\n"
     ]
    }
   ],
   "source": [
    "base_info=pd.read_csv('data/train/base_info.csv')#企业的基本信息\n",
    "annual_report_info=pd.read_csv('data/train/annual_report_info.csv')#企业的年报基本信息\n",
    "tax_info=pd.read_csv('data/train/tax_info.csv')#企业的纳税信息\n",
    "change_info=pd.read_csv('data/train/tax_info.csv')#变更信息\n",
    "news_info=pd.read_csv('data/train/news_info.csv')#舆情信息\n",
    "other_info=pd.read_csv('data/train/other_info.csv')#其它信息\n",
    "entprise_info=pd.read_csv('data/train/entprise_info.csv')#企业标注信息{0: 13884, 1: 981}\n",
    "entprise_evaluate=pd.read_csv('data/entprise_evaluate.csv')#未标注信息\n",
    "\n",
    "print('base_info shape:',base_info.shape,'id unique:',len(base_info['id'].unique()))\n",
    "print('annual_report_info shape:',annual_report_info.shape,'id unique:',len(annual_report_info['id'].unique()))\n",
    "print('tax_info shape:',tax_info.shape,'id unique:',len(tax_info['id'].unique()))\n",
    "print('change_info shape:',change_info.shape,'id unique:',len(change_info['id'].unique()))\n",
    "print('news_info shape:',news_info.shape,'id unique:',len(news_info['id'].unique()))\n",
    "print('other_info shape:',other_info.shape,'id unique:',len(other_info['id'].unique()))\n",
    "print('entprise_info shape:',entprise_info.shape,'id unique:',len(entprise_info['id'].unique()))\n",
    "print('entprise_evaluate shape:',entprise_evaluate.shape,'id unique:',len(entprise_evaluate['id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "base_info['opfrom'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初步数据探索\n",
    "除了企业的基本信息较为齐全外，其余各表信息均有缺失。很多企业id空缺\n",
    "训练集总共14865条样本，其中正例:13884,负例981.约为14:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(13884, 981, 14.15290519877676)"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "#下面看一下具有企业年报信息和纳税信息的企业有多少是非法集资的企业\n",
    "#首先筛选出非法集资的企业\n",
    "illegal_id_list=[]\n",
    "legal_id_list=[]\n",
    "for index,name_id,flag in entprise_info.itertuples():\n",
    "    if flag==1:\n",
    "        illegal_id_list.append(name_id)\n",
    "    else:\n",
    "        legal_id_list.append(name_id)\n",
    "len(legal_id_list),len(illegal_id_list),len(legal_id_list)/len(illegal_id_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "具有年报基本信息的企业中，有536违法；2800合法；5601为测试集\n",
      "不具有年报基本信息的企业中，有445违法；11084合法\n",
      "具有年报基本信息的企业中：合法/违法:5.223880597014926\n",
      "不具有年报基本信息的企业中：合法/违法:24.907865168539328\n",
      "具有税收基本信息的企业中，有75违法；99合法；634为测试集\n",
      "不具有税收基本信息的企业中，有906违法；13785合法\n",
      "具有税收基本信息的企业中：合法/违法:1.32\n",
      "不具有税收基本信息的企业中：合法/违法:15.21523178807947\n",
      "具有变更信息基本信息的企业中，有75违法；99合法；634为测试集\n",
      "不具有变更信息基本信息的企业中，有906违法；13785合法\n",
      "具有变更信息基本信息的企业中：合法/违法:1.32\n",
      "不具有变更信息基本信息的企业中：合法/违法:15.21523178807947\n",
      "具有舆情信息基本信息的企业中，有156违法；232合法；539为测试集\n",
      "不具有舆情信息基本信息的企业中，有825违法；13652合法\n",
      "具有舆情信息基本信息的企业中：合法/违法:1.4871794871794872\n",
      "不具有舆情信息基本信息的企业中：合法/违法:16.547878787878787\n",
      "具有其它信息基本信息的企业中，有139违法；697合法；1052为测试集\n",
      "不具有其它信息基本信息的企业中，有842违法；13187合法\n",
      "具有其它信息基本信息的企业中：合法/违法:5.014388489208633\n",
      "不具有其它信息基本信息的企业中：合法/违法:15.661520190023753\n"
     ]
    }
   ],
   "source": [
    "#................ 查看各数据集合中违法和合法的评估信息...............#\n",
    "def caculate_state__info(legal_id_list,illegal_id_list,name,data):\n",
    "    state = {'-1':0,'0':0,'1':0}\n",
    "    for i in data['id'].unique():\n",
    "        if i in illegal_id_list:\n",
    "            state['1']+=1\n",
    "        elif i in legal_id_list:\n",
    "            state['0']+=1\n",
    "        else:\n",
    "            state['-1']+=1\n",
    "    legal_num,illegal_num = len(legal_id_list),len(illegal_id_list)\n",
    "    print(\"具有{}基本信息的企业中，有{}违法；{}合法；{}为测试集\".format(name,state['1'],state['0'],state['-1']))\n",
    "    print(\"不具有{}基本信息的企业中，有{}违法；{}合法\".format(name,illegal_num-state['1'],legal_num-state['0']))\n",
    "    print(\"具有{}基本信息的企业中：合法/违法:{}\".format(name,(state['0']/state['1'])))\n",
    "    print(\"不具有{}基本信息的企业中：合法/违法:{}\".format(name,(legal_num-state['0'])/(illegal_num-state['1'])))\n",
    "\n",
    "# #..................年报基本信息信息数据...................\n",
    "caculate_state__info(legal_id_list,illegal_id_list,'年报',annual_report_info)\n",
    "# #...........................纳税信息news_info....................\n",
    "caculate_state__info(legal_id_list,illegal_id_list,'税收',tax_info) \n",
    "#.................. 变更信息 change_info.................\n",
    "caculate_state__info(legal_id_list,illegal_id_list,'变更信息',change_info) \n",
    "#.................. 舆情信息 news_info.................\n",
    "caculate_state__info(legal_id_list,illegal_id_list,'舆情信息',news_info)\n",
    "#.................. 其它信息 other_info.................\n",
    "caculate_state__info(legal_id_list,illegal_id_list,'其它信息',other_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                    id  STATE  EMPNUM  \\\n",
       "0     9c7fa510616a683058ce97d0bc768a621cd85ab1e87da2a3    2.0    6.00   \n",
       "1     9c7fa510616a68309e4badf2a7a3123c0462fb85bf28ef17    2.0   16.00   \n",
       "2     755db3b5c5f74eb48564a8be9d4a9d7038ed96bc2eea645c    2.0    1.00   \n",
       "3     da8691b210adb3f6334a7abb56fbae858620b23304f160b5    2.0    1.75   \n",
       "4     755db3b5c5f74eb46a9abdca3e43a99d07c4aacee3d2cb0d    2.0    1.00   \n",
       "...                                                ...    ...     ...   \n",
       "8932  d8071a739aa75a3be9069415a33734b8e3044ccc7b18fe59    2.0    1.00   \n",
       "8933  d8071a739aa75a3b1e6a0b92c454b72de9a5a524209a60f5    2.0    1.00   \n",
       "8934  f000950527a6feb6d121d68000403ba01bbfb7813e9f7c51    2.0    1.00   \n",
       "8935  f000950527a6feb6df93ef17ecca21b6b1122d72587f4360    2.0    0.00   \n",
       "8936  f000950527a6feb6cbab26794aaba6ab56f85a08923e9677    2.0    3.00   \n",
       "\n",
       "      EMPNUMSIGN  BUSSTNAME  COLGRANUM  RETSOLNUM  DISPERNUM  UNENUM  \\\n",
       "0           -1.0       -1.0        0.0        0.0        0.0     0.0   \n",
       "1           -1.0       -1.0        0.0        0.0        0.0     0.0   \n",
       "2           -1.0       -1.0        0.0        0.0        0.0     0.0   \n",
       "3           -1.0       -1.0        0.0        0.0        0.0     0.5   \n",
       "4           -1.0       -1.0        0.0        0.0        0.0     0.0   \n",
       "...          ...        ...        ...        ...        ...     ...   \n",
       "8932         2.0        3.0        1.0        0.0        0.0     0.0   \n",
       "8933         2.0        3.0        0.0        0.0        0.0     0.0   \n",
       "8934         2.0        3.0       -1.0       -1.0       -1.0    -1.0   \n",
       "8935         2.0        3.0        0.0        0.0        0.0     0.0   \n",
       "8936         1.0        3.0        3.0        0.0        0.0     0.0   \n",
       "\n",
       "      COLEMPLNUM  RETEMPLNUM  DISEMPLNUM  UNEEMPLNUM  WEBSITSIGN  \\\n",
       "0            0.0         0.0         0.0        0.00         2.0   \n",
       "1            0.0         0.0         0.0        0.00         2.0   \n",
       "2            0.0         0.0         0.0        0.00         2.0   \n",
       "3            0.0         0.0         0.0        0.75         2.0   \n",
       "4            0.0         0.0         0.0        0.00         2.0   \n",
       "...          ...         ...         ...         ...         ...   \n",
       "8932         0.0         0.0         0.0        0.00         2.0   \n",
       "8933         1.0         0.0         0.0        0.00         2.0   \n",
       "8934        -1.0        -1.0        -1.0       -1.00         2.0   \n",
       "8935         0.0         0.0         0.0        0.00         1.0   \n",
       "8936         0.0         0.0         0.0        0.00         2.0   \n",
       "\n",
       "      FORINVESTSIGN  STOCKTRANSIGN  PUBSTATE  \n",
       "0              -1.0           -1.0       3.0  \n",
       "1              -1.0           -1.0       3.0  \n",
       "2              -1.0           -1.0       3.0  \n",
       "3              -1.0           -1.0       3.0  \n",
       "4              -1.0           -1.0       3.0  \n",
       "...             ...            ...       ...  \n",
       "8932            2.0            2.0       3.0  \n",
       "8933            2.0            2.0       3.0  \n",
       "8934            2.0            2.0       3.0  \n",
       "8935            2.0            2.0       3.0  \n",
       "8936            2.0            2.0       1.0  \n",
       "\n",
       "[8937 rows x 17 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>STATE</th>\n      <th>EMPNUM</th>\n      <th>EMPNUMSIGN</th>\n      <th>BUSSTNAME</th>\n      <th>COLGRANUM</th>\n      <th>RETSOLNUM</th>\n      <th>DISPERNUM</th>\n      <th>UNENUM</th>\n      <th>COLEMPLNUM</th>\n      <th>RETEMPLNUM</th>\n      <th>DISEMPLNUM</th>\n      <th>UNEEMPLNUM</th>\n      <th>WEBSITSIGN</th>\n      <th>FORINVESTSIGN</th>\n      <th>STOCKTRANSIGN</th>\n      <th>PUBSTATE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9c7fa510616a683058ce97d0bc768a621cd85ab1e87da2a3</td>\n      <td>2.0</td>\n      <td>6.00</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>2.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9c7fa510616a68309e4badf2a7a3123c0462fb85bf28ef17</td>\n      <td>2.0</td>\n      <td>16.00</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>2.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>755db3b5c5f74eb48564a8be9d4a9d7038ed96bc2eea645c</td>\n      <td>2.0</td>\n      <td>1.00</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>2.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>da8691b210adb3f6334a7abb56fbae858620b23304f160b5</td>\n      <td>2.0</td>\n      <td>1.75</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.75</td>\n      <td>2.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>755db3b5c5f74eb46a9abdca3e43a99d07c4aacee3d2cb0d</td>\n      <td>2.0</td>\n      <td>1.00</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>2.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8932</th>\n      <td>d8071a739aa75a3be9069415a33734b8e3044ccc7b18fe59</td>\n      <td>2.0</td>\n      <td>1.00</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>8933</th>\n      <td>d8071a739aa75a3b1e6a0b92c454b72de9a5a524209a60f5</td>\n      <td>2.0</td>\n      <td>1.00</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>8934</th>\n      <td>f000950527a6feb6d121d68000403ba01bbfb7813e9f7c51</td>\n      <td>2.0</td>\n      <td>1.00</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.00</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>8935</th>\n      <td>f000950527a6feb6df93ef17ecca21b6b1122d72587f4360</td>\n      <td>2.0</td>\n      <td>0.00</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>8936</th>\n      <td>f000950527a6feb6cbab26794aaba6ab56f85a08923e9677</td>\n      <td>2.0</td>\n      <td>3.00</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8937 rows × 17 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "#处理base_info的数据\n",
    "#空值大于0.5的列都删除掉\n",
    "annual_report_info_clean=annual_report_info.dropna(thresh=annual_report_info.shape[0]*0.5,how='all',axis=1)\n",
    "#对object类型进行编码\n",
    "annual_report_info_clean['BUSSTNAME']=annual_report_info_clean['BUSSTNAME'].fillna(\"无\")\n",
    "dic = {'无':-1,'开业':0, '歇业':1, '停业':2, '清算':3}\n",
    "buf = pd.DataFrame()\n",
    "buf_group = annual_report_info_clean.groupby('BUSSTNAME',sort=False)\n",
    "for name,group in buf_group:\n",
    "    group['BUSSTNAME'] = dic[name]\n",
    "    buf = pd.concat([buf,group],ignore_index=True)\n",
    "buf=buf.fillna(-1)\n",
    "#\n",
    "buf_group = buf.groupby('id',sort=False).agg('mean')\n",
    "buf=pd.DataFrame(buf_group).reset_index()\n",
    "annual_report_info_clean=buf.drop(['ANCHEYEAR'],axis=1)\n",
    "annual_report_info_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   id  TAX_CATEGORIES  \\\n",
       "0    f000950527a6feb6c2f40c9d8477e73a439dfa0897830397        0.566667   \n",
       "1    f000950527a6feb67cc398bac3bff4a69b4aaa096f975b20        4.254613   \n",
       "2    f000950527a6feb6891a8c7d5bb8af4bcfaebfe4ccc87efb        3.981744   \n",
       "3    f000950527a6feb6a4001d4d055bc17b81559375dfc8786d        3.828947   \n",
       "4    f000950527a6feb6fa6bfc4fe01a9ae5dc3880b78f177c88        1.783831   \n",
       "..                                                ...             ...   \n",
       "803  d8071a739aa75a3bf8caa850961981d09933dc800349ea63       13.000000   \n",
       "804  f000950527a6feb6bd741f7ffa1590df1b85051f3be8cdd1       13.000000   \n",
       "805  f000950527a6feb613b84f384d8bca7305b7451d3f150040       13.000000   \n",
       "806  516ab81418ed215d355ce73ceacf29904268b934709af50e       15.000000   \n",
       "807  f000950527a6feb694d7a6401f1c9e95c1931db540c08e76       16.000000   \n",
       "\n",
       "      TAX_ITEMS  TAXATION_BASIS  TAX_RATE      DEDUCTION     TAX_AMOUNT  \n",
       "0     63.966667    4.401121e+04 -0.150153      -0.190667      70.029667  \n",
       "1     46.780443    8.276959e+07  0.152374    8702.194926  702578.461070  \n",
       "2     48.626775    1.150764e+06  2.970030   98943.244260    9253.740548  \n",
       "3     56.022556    7.728593e+06  2.076662  264166.707726   61653.046015  \n",
       "4     30.991213    4.592809e+08  0.054007    1561.159649  131296.811705  \n",
       "..          ...             ...       ...            ...            ...  \n",
       "803  271.000000   -1.000000e+00 -1.000000      -1.000000     500.000000  \n",
       "804  271.000000   -1.000000e+00 -1.000000      -1.000000      80.000000  \n",
       "805  271.000000   -1.000000e+00 -1.000000      -1.000000    2000.000000  \n",
       "806  273.000000   -1.000000e+00 -1.000000      -1.000000    2000.000000  \n",
       "807  274.000000   -1.000000e+00 -1.000000      -1.000000       4.200000  \n",
       "\n",
       "[808 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>TAX_CATEGORIES</th>\n      <th>TAX_ITEMS</th>\n      <th>TAXATION_BASIS</th>\n      <th>TAX_RATE</th>\n      <th>DEDUCTION</th>\n      <th>TAX_AMOUNT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>f000950527a6feb6c2f40c9d8477e73a439dfa0897830397</td>\n      <td>0.566667</td>\n      <td>63.966667</td>\n      <td>4.401121e+04</td>\n      <td>-0.150153</td>\n      <td>-0.190667</td>\n      <td>70.029667</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>f000950527a6feb67cc398bac3bff4a69b4aaa096f975b20</td>\n      <td>4.254613</td>\n      <td>46.780443</td>\n      <td>8.276959e+07</td>\n      <td>0.152374</td>\n      <td>8702.194926</td>\n      <td>702578.461070</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>f000950527a6feb6891a8c7d5bb8af4bcfaebfe4ccc87efb</td>\n      <td>3.981744</td>\n      <td>48.626775</td>\n      <td>1.150764e+06</td>\n      <td>2.970030</td>\n      <td>98943.244260</td>\n      <td>9253.740548</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>f000950527a6feb6a4001d4d055bc17b81559375dfc8786d</td>\n      <td>3.828947</td>\n      <td>56.022556</td>\n      <td>7.728593e+06</td>\n      <td>2.076662</td>\n      <td>264166.707726</td>\n      <td>61653.046015</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>f000950527a6feb6fa6bfc4fe01a9ae5dc3880b78f177c88</td>\n      <td>1.783831</td>\n      <td>30.991213</td>\n      <td>4.592809e+08</td>\n      <td>0.054007</td>\n      <td>1561.159649</td>\n      <td>131296.811705</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>803</th>\n      <td>d8071a739aa75a3bf8caa850961981d09933dc800349ea63</td>\n      <td>13.000000</td>\n      <td>271.000000</td>\n      <td>-1.000000e+00</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>500.000000</td>\n    </tr>\n    <tr>\n      <th>804</th>\n      <td>f000950527a6feb6bd741f7ffa1590df1b85051f3be8cdd1</td>\n      <td>13.000000</td>\n      <td>271.000000</td>\n      <td>-1.000000e+00</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>80.000000</td>\n    </tr>\n    <tr>\n      <th>805</th>\n      <td>f000950527a6feb613b84f384d8bca7305b7451d3f150040</td>\n      <td>13.000000</td>\n      <td>271.000000</td>\n      <td>-1.000000e+00</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>2000.000000</td>\n    </tr>\n    <tr>\n      <th>806</th>\n      <td>516ab81418ed215d355ce73ceacf29904268b934709af50e</td>\n      <td>15.000000</td>\n      <td>273.000000</td>\n      <td>-1.000000e+00</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>2000.000000</td>\n    </tr>\n    <tr>\n      <th>807</th>\n      <td>f000950527a6feb694d7a6401f1c9e95c1931db540c08e76</td>\n      <td>16.000000</td>\n      <td>274.000000</td>\n      <td>-1.000000e+00</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>4.200000</td>\n    </tr>\n  </tbody>\n</table>\n<p>808 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "#处理tax数据\n",
    "tax_info_clean=tax_info.drop(['START_DATE','END_DATE'],axis=1)\n",
    "tax_info_clean['TAX_CATEGORIES']=tax_info_clean['TAX_CATEGORIES'].fillna(\"无\")\n",
    "tax_info_clean['TAX_ITEMS']=tax_info_clean['TAX_ITEMS'].fillna(\"无\")\n",
    "#对object类型进行编码\n",
    "# tax_info_clean['BUSSTNAME']=tax_infoclean['BUSSTNAME'].fillna(\"无\")\n",
    "dic={}\n",
    "cate=tax_info.TAX_CATEGORIES.unique()\n",
    "for i in range(len(cate)):\n",
    "    dic[cate[i]]=i\n",
    "\n",
    "buf = pd.DataFrame()\n",
    "buf_group = tax_info_clean.groupby('TAX_CATEGORIES',sort=False)\n",
    "for name,group in buf_group:\n",
    "    group['TAX_CATEGORIES'] = dic[name]\n",
    "    buf = pd.concat([buf,group],ignore_index=True)\n",
    "\n",
    "#\n",
    "dic={}\n",
    "cate=buf.TAX_ITEMS.unique()\n",
    "for i in range(len(cate)):\n",
    "    dic[cate[i]]=i\n",
    "\n",
    "buf_group = buf.groupby('TAX_ITEMS',sort=False)\n",
    "buf = pd.DataFrame()\n",
    "for name,group in buf_group:\n",
    "    group['TAX_ITEMS'] = dic[name]\n",
    "    buf = pd.concat([buf,group],ignore_index=True)\n",
    "buf=buf.fillna(-1)\n",
    "#\n",
    "buf_group = buf.groupby('id',sort=False).agg('mean')\n",
    "tax_info_clean=pd.DataFrame(buf_group).reset_index()\n",
    "tax_info_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "finished 1....\n",
      "finished 3....\n",
      "finished 4....\n",
      "编码完毕.................\n"
     ]
    }
   ],
   "source": [
    "# #处理base_info数据\n",
    "\n",
    "# 把缺失数量作为一种编码\n",
    "base_info_clean = base_info\n",
    "base_info_clean['nan_num'] = base_info.isnull().sum(axis=1)\n",
    "base_info_clean = base_info_clean.drop(['opscope','opfrom','opto','dom'],axis=1)\n",
    "\n",
    "\n",
    "#............................对object类型进行编码...............................\n",
    "base_info_clean['industryphy']=base_info_clean['industryphy'].fillna(\"无\")\n",
    "# base_info_clean['dom']=base_info_clean['dom'].fillna(\"无\")\n",
    "base_info_clean['opform']=base_info_clean['opform'].fillna(\"无\")\n",
    "base_info_clean['oploc']=base_info_clean['oploc'].fillna(\"无\")\n",
    "\n",
    "dic={}\n",
    "cate=base_info_clean.industryphy.unique()\n",
    "for i in range(len(cate)):\n",
    "    dic[cate[i]]=i\n",
    "\n",
    "buf = pd.DataFrame()\n",
    "buf_group = base_info_clean.groupby('industryphy',sort=False)\n",
    "for name,group in buf_group:\n",
    "    group['industryphy'] = dic[name]\n",
    "    buf = pd.concat([buf,group],ignore_index=True)\n",
    "print('finished 1....')\n",
    "#\n",
    "# dic={}\n",
    "# cate=buf.dom.unique()\n",
    "# for i in range(len(cate)):\n",
    "#     dic[cate[i]]=i\n",
    "\n",
    "# buf_group = buf.groupby('dom',sort=False)\n",
    "# buf = pd.DataFrame()\n",
    "# for name,group in buf_group:\n",
    "#     group['dom'] = dic[name]\n",
    "#     buf = pd.concat([buf,group],ignore_index=True)\n",
    "# print('finished 2....')\n",
    "#\n",
    "dic={}\n",
    "cate=buf.opform.unique()\n",
    "for i in range(len(cate)):\n",
    "    dic[cate[i]]=i\n",
    "\n",
    "buf_group = buf.groupby('opform',sort=False)\n",
    "buf = pd.DataFrame()\n",
    "for name,group in buf_group:\n",
    "    group['opform'] = dic[name]\n",
    "    buf = pd.concat([buf,group],ignore_index=True)\n",
    "print('finished 3....')\n",
    "#\n",
    "dic={}\n",
    "cate=buf.oploc.unique()\n",
    "for i in range(len(cate)):\n",
    "    dic[cate[i]]=i\n",
    "\n",
    "buf_group = buf.groupby('oploc',sort=False)\n",
    "buf = pd.DataFrame()\n",
    "for name,group in buf_group:\n",
    "    group['oploc'] = dic[name]\n",
    "    buf = pd.concat([buf,group],ignore_index=True)\n",
    "print('finished 4....')\n",
    "\n",
    "buf=buf.fillna(-1)\n",
    "\n",
    "buf_group = buf.groupby('id',sort=False).agg('mean')\n",
    "base_info_clean=pd.DataFrame(buf_group).reset_index()\n",
    "\n",
    "print('编码完毕.................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 20%|██        | 5022/24865 [00:00<00:00, 50217.89it/s]分桶完毕.................\n",
      "100%|██████████| 24865/24865 [00:00<00:00, 59591.97it/s]\n",
      "100%|██████████| 24865/24865 [00:00<00:00, 113427.50it/s]交叉特征完毕.................\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#........................分桶.................................\n",
    "def bucket(name,bucket_len):\n",
    "    gap_list=[base_info_clean[name].quantile(i/bucket_len) for i in range(bucket_len+1)]\n",
    "    len_data=len(base_info_clean[name])\n",
    "    new_col=[]\n",
    "    for i in base_info_clean[name].values:\n",
    "        for j in range(len(gap_list)):\n",
    "            if gap_list[j]>=i:\n",
    "                encode=j\n",
    "                break\n",
    "        new_col.append(encode)\n",
    "    return new_col\n",
    "#注册资本_实缴资本\n",
    "base_info_clean['regcap_reccap']=base_info_clean['regcap']-base_info_clean['reccap']\n",
    "#注册资本分桶\n",
    "base_info_clean['regcap']=base_info_clean['regcap'].fillna(base_info_clean['regcap'].median())\n",
    "base_info_clean['bucket_regcap']=bucket('regcap',5)\n",
    "#实缴资本分桶\n",
    "base_info_clean['reccap']=base_info_clean['reccap'].fillna(base_info_clean['reccap'].median())\n",
    "base_info_clean['bucket_reccap']=bucket('reccap',5)\n",
    "#注册资本_实缴资本分桶\n",
    "base_info_clean['regcap_reccap']=base_info_clean['regcap_reccap'].fillna(base_info_clean['regcap_reccap'].median())\n",
    "base_info_clean['bucket_regcap_reccap']=bucket('regcap_reccap',5)\n",
    "\n",
    "# 缺失数量分桶\n",
    "base_info_clean['bucket_nan_num'] = bucket('regcap_reccap',5)\n",
    "print('分桶完毕.................')\n",
    "#.............................交叉.........................\n",
    "#作两个特征的交叉\n",
    "def cross_two(name_1,name_2):\n",
    "    new_col=[]\n",
    "    encode=0\n",
    "    dic={}\n",
    "    val_1=base_info[name_1]\n",
    "    val_2=base_info[name_2]\n",
    "    for i in tqdm(range(len(val_1))):\n",
    "        tmp=str(val_1[i])+'_'+str(val_2[i])\n",
    "        if tmp in dic:\n",
    "            new_col.append(dic[tmp])\n",
    "        else:\n",
    "            dic[tmp]=encode\n",
    "            new_col.append(encode)\n",
    "            encode+=1\n",
    "    return new_col\n",
    "#作企业类型-小类的交叉特征\n",
    "base_info_clean['enttypegb']=base_info_clean['enttypegb'].fillna(\"无\")\n",
    "base_info_clean['enttypeitem']=base_info_clean['enttypeitem'].fillna(\"无\")\n",
    "new_col=cross_two('enttypegb','enttypeitem')#作企业类型-小类的交叉特征\n",
    "base_info_clean['enttypegb_enttypeitem']=new_col\n",
    "#\n",
    "#行业类别-细类的交叉特征\n",
    "base_info_clean['industryphy']=base_info_clean['industryphy'].fillna(\"无\")\n",
    "base_info_clean['industryco']=base_info_clean['industryco'].fillna(\"无\")\n",
    "new_col=cross_two('industryphy','industryco')#作企业类型-小类的交叉特征\n",
    "base_info_clean['industryphy_industryco']=new_col\n",
    "print('交叉特征完毕.................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features=['industryphy','opform','oploc','bucket_regcap',\n",
    "              'bucket_reccap','bucket_regcap_reccap',\n",
    "              'enttypegb','enttypeitem','enttypegb_enttypeitem',\n",
    "              'industryphy','industryco','industryphy_industryco',\n",
    "              'adbusign','townsign','regtype','TAX_CATEGORIES'\n",
    "             ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((24865, 59), (24865, 34), (22550, 23), (29195, 9))"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "#暂时可以利用企业基本信息，企业纳税信息，企业年度财报信息做义工merge然后进行我们的分类工作\n",
    "all_data=base_info_clean.merge(annual_report_info_clean,how='outer')\n",
    "all_data=all_data.merge(tax_info_clean,how='outer')\n",
    "all_data=all_data.fillna(-1)\n",
    "all_data.shape,base_info.shape,annual_report_info.shape,tax_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[cat_features]=all_data[cat_features].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((14865, 58), (10000, 58))"
      ]
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "source": [
    "#train_data=all_data[all_data['id'].isin(entprise_info['id'].unique().tolist())]\n",
    "#train_data=train_data.reset_index(drop=True)\n",
    "train_df=all_data.merge(entprise_info)\n",
    "train_data=train_df.drop(['id','label'],axis=1)\n",
    "kind=train_df['label']\n",
    "test_df=all_data[all_data['id'].isin(entprise_evaluate['id'].unique().tolist())]\n",
    "test_df=test_df.reset_index(drop=True)\n",
    "test_data=test_df.drop(['id'],axis=1)\n",
    "train_data.shape,test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征筛选\n",
    "#frt_select=[\n",
    "#  'industryco','industryphy','regcap','reccap',\n",
    "#  'regcap_reccap','enttypegb','enttypeitem','adbusign','TAX_CATEGORIES',\n",
    "#  'townsign','empnum','TAX_AMOUNT','industryphy_industryco',\n",
    "#  'venind','enttypeminu','EMPNUM','COLGRANUM',\n",
    "#  'dom','jobid','enttypegb_enttypeitem','parnum','bucket_regcap',\n",
    "#  'exenum','opform','bucket_reccap','oplocdistrict','TAX_ITEMS',\n",
    "#  'bucket_regcap_reccap','orgid','COLEMPLNUM','FORINVESTSIGN',\n",
    "#  'BUSSTNAME','compform','regtype','RETEMPLNUM','STATE','EMPNUMSIGN','enttype','UNEEMPLNUM',\n",
    "# ]\n",
    "# train_data=train_data[frt_select]\n",
    "# test_data=test_data[frt_select]\n",
    "# cat_features=list(set(frt_select).intersection(set(cat_features)))\n",
    "# cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_score(y_test,y_pre):\n",
    "    _,_,f_class,_=precision_recall_fscore_support(y_true=y_test,y_pred=y_pre,labels=[0,1],average=None)\n",
    "    fper_class={'合法':f_class[0],'违法':f_class[1],'f1':f1_score(y_test,y_pre)}\n",
    "    return fper_class\n",
    "#\n",
    "def k_fold_serachParmaters(model,train_val_data,train_val_kind):\n",
    "    mean_f1=0\n",
    "    mean_f1Train=0\n",
    "    n_splits=5\n",
    "    sk = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2020)\n",
    "    for train, test in sk.split(train_val_data, train_val_kind):\n",
    "        x_train = train_val_data.iloc[train]\n",
    "        y_train = train_val_kind.iloc[train]\n",
    "        x_test = train_val_data.iloc[test]\n",
    "        y_test = train_val_kind.iloc[test]\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        pred = model.predict(x_test)\n",
    "        fper_class =  eval_score(y_test,pred)\n",
    "        mean_f1+=fper_class['f1']/n_splits\n",
    "        #print(fper_class)\n",
    "        \n",
    "        pred_Train = model.predict(x_train)\n",
    "        fper_class_train =  eval_score(y_train,pred_Train)\n",
    "        mean_f1Train+=fper_class_train['f1']/n_splits\n",
    "    #print('mean valf1:',mean_f1)\n",
    "    #print('mean trainf1:',mean_f1Train)\n",
    "    return mean_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iter_cnt: 55\n",
      "[55, 0.05, 5] 0.823627697409949\n",
      "[55, 0.05, 6] 0.8296895830730766\n",
      "[55, 0.055, 7] 0.8323499588860255\n",
      "[55, 0.06, 8] 0.8382743912370926\n",
      "[55, 0.065, 8] 0.8390257168838791\n",
      "iter_cnt: 60\n",
      "iter_cnt: 70\n"
     ]
    }
   ],
   "source": [
    "def search_param(iter_cnt,lr,max_depth):\n",
    "    clf=cab.CatBoostClassifier(iterations=iter_cnt\n",
    "                              ,learning_rate=lr\n",
    "                              ,depth=max_depth\n",
    "                              ,silent=True\n",
    "                              ,thread_count=8\n",
    "                              ,task_type='CPU'\n",
    "                              ,cat_features=cat_features\n",
    "                              )\n",
    "    mean_f1=k_fold_serachParmaters(clf,train_data,kind)\n",
    "    return mean_f1\n",
    "\n",
    "#搜索最佳参数\n",
    "param=[]\n",
    "best=0\n",
    "for iter_cnt in [55,60,70]:\n",
    "    print('iter_cnt:',iter_cnt)\n",
    "    for lr in [0.050,0.055,0.060,0.065]:\n",
    "        for max_depth in [5,6,7,8]:\n",
    "            mean_f1=search_param(iter_cnt,lr,max_depth)\n",
    "            if mean_f1>best:\n",
    "                param=[iter_cnt,lr,max_depth]\n",
    "                best=mean_f1\n",
    "                print(param,best)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "n_estimators: 57\n",
      "[57, 6, 11] 0.822567026484206\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-eec04dd6cad1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmin_samples_split\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mmean_f1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmean_f1\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mparam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-131-eec04dd6cad1>\u001b[0m in \u001b[0;36msearch_param\u001b[0;34m(n_estimators, max_depth, min_samples_split)\u001b[0m\n\u001b[1;32m      5\u001b[0m     rf = RandomForestClassifier(oob_score=True, random_state=2020,\n\u001b[1;32m      6\u001b[0m                     n_estimators= n_estimators,max_depth=max_depth,min_samples_split=min_samples_split)\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmean_f1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_fold_serachParmaters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmean_f1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-3c8df2d8dbd4>\u001b[0m in \u001b[0;36mk_fold_serachParmaters\u001b[0;34m(model, train_val_data, train_val_kind)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m#print(fper_class)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mpred_Train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mfper_class_train\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0meval_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_Train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mmean_f1Train\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mfper_class_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \"\"\"\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    684\u001b[0m             delayed(_accumulate_prediction)(e.predict_proba, X, all_proba,\n\u001b[1;32m    685\u001b[0m                                             lock)\n\u001b[0;32m--> 686\u001b[0;31m             for e in self.estimators_)\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mproba\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ml/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ml/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_accumulate_prediction\u001b[0;34m(predict, X, out, lock)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0mcomplains\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mit\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mpickle\u001b[0m \u001b[0mit\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mplaced\u001b[0m \u001b[0mthere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "\n",
    "def search_param(n_estimators,max_depth,min_samples_split):\n",
    "    rf = RandomForestClassifier(oob_score=True, random_state=2020,\n",
    "                    n_estimators= n_estimators,max_depth=max_depth,min_samples_split=min_samples_split)\n",
    "    mean_f1=k_fold_serachParmaters(rf,train_data,kind)\n",
    "    return mean_f1\n",
    "\n",
    "#搜索最佳参数\n",
    "param=[]\n",
    "best=0\n",
    "for n_estimators in [57,58,59,60,65]:\n",
    "    print('n_estimators:',n_estimators)\n",
    "    for min_samples_split in [6,7,8,10,13,15]:\n",
    "        for max_depth in [11,12,13,15]:\n",
    "            mean_f1=search_param(n_estimators,max_depth,min_samples_split)\n",
    "            if mean_f1>best:\n",
    "                param=[n_estimators,min_samples_split,max_depth]\n",
    "                best=mean_f1\n",
    "                print(param,best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, train_data, train_label, test_data,n_splits = 5, shuffle = True,random_state=2020):\n",
    "    mean_f1 = 0\n",
    "    answers = []\n",
    "    feature_importance_list = []\n",
    "    sk = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2020)\n",
    "    for i, (train, valid) in enumerate(sk.split(train_data, train_label)):\n",
    "        x_train = train_data.iloc[train]\n",
    "        y_train = train_label.iloc[train]\n",
    "        x_valid = train_data.iloc[valid]\n",
    "        y_valid = train_label.iloc[valid]\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        pred_cab = model.predict(x_valid)\n",
    "        f1_score =  eval_score(y_valid,pred_cab)['f1']\n",
    "        print('model = {} 第{}次验证的f1:{}'.format(model,i+1,f1_score))\n",
    "        feature_importance = pd.DataFrame({\n",
    "        'column': train_data.columns,\n",
    "        'importance': model.feature_importances_,\n",
    "        })\n",
    "        feature_importance_list.append(feature_importance)\n",
    "        mean_f1 += f1_score/n_splits\n",
    "        ans = model.predict_proba(test_data)\n",
    "        answers.append(ans)\n",
    "    print('mean f1:',mean_f1)\n",
    "    feature_importances = pd.concat(feature_importance_list)\n",
    "    feature_importances = feature_importances.groupby(\n",
    "    'column')['importance'].agg('mean').sort_values(ascending=False).reset_index()\n",
    "    return np.sqrt(sum(np.array(answers)**2)/n_splits)[:,1], feature_importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "model = RandomForestClassifier(max_depth=13, min_samples_split=6, n_estimators=60,\n",
      "                       oob_score=True, random_state=2020) 第1次验证的f1:0.8465346534653465\n",
      "model = RandomForestClassifier(max_depth=13, min_samples_split=6, n_estimators=60,\n",
      "                       oob_score=True, random_state=2020) 第2次验证的f1:0.8050632911392406\n",
      "model = RandomForestClassifier(max_depth=13, min_samples_split=6, n_estimators=60,\n",
      "                       oob_score=True, random_state=2020) 第3次验证的f1:0.846153846153846\n",
      "model = RandomForestClassifier(max_depth=13, min_samples_split=6, n_estimators=60,\n",
      "                       oob_score=True, random_state=2020) 第4次验证的f1:0.8295165394402036\n",
      "model = RandomForestClassifier(max_depth=13, min_samples_split=6, n_estimators=60,\n",
      "                       oob_score=True, random_state=2020) 第5次验证的f1:0.8142493638676845\n",
      "mean f1: 0.8283035388132642\n",
      "model = <catboost.core.CatBoostClassifier object at 0x1a28511550> 第1次验证的f1:0.8557213930348259\n",
      "model = <catboost.core.CatBoostClassifier object at 0x1a28511550> 第2次验证的f1:0.8184143222506394\n",
      "model = <catboost.core.CatBoostClassifier object at 0x1a28511550> 第3次验证的f1:0.85012285012285\n",
      "model = <catboost.core.CatBoostClassifier object at 0x1a28511550> 第4次验证的f1:0.8300000000000002\n",
      "model = <catboost.core.CatBoostClassifier object at 0x1a28511550> 第5次验证的f1:0.8211586901763224\n",
      "mean f1: 0.8350834511169275\n"
     ]
    }
   ],
   "source": [
    "clf=cab.CatBoostClassifier(iterations=55\n",
    "                              ,learning_rate=0.065\n",
    "                              ,depth=8\n",
    "                              ,silent=True\n",
    "                              ,thread_count=8\n",
    "                              ,task_type='CPU'\n",
    "                              ,cat_features=cat_features\n",
    "                              )\n",
    "\n",
    "rf = RandomForestClassifier(oob_score=True, random_state=2020,\n",
    "            n_estimators= 60,max_depth=13,min_samples_split=6)\n",
    "\n",
    "\n",
    "rf_score,rf_feature_importances = predict(rf,train_data,kind,test_data)\n",
    "cat_score,cat_feature_importances = predict(clf,train_data,kind,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "final_score = (rf_score + cat_score)/2.0\n",
    "test_df['score'] = final_score #可选:fina_persudo是伪标签的预测结果\n",
    "submit_csv=test_df[['id','score']]\n",
    "submit_csv.to_csv('submit.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        column  importance\n",
       "0   industryco    0.223530\n",
       "1       exenum    0.082331\n",
       "2  industryphy    0.079328\n",
       "3  enttypeitem    0.064778\n",
       "4  enttypeminu    0.057838"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>column</th>\n      <th>importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>industryco</td>\n      <td>0.223530</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>exenum</td>\n      <td>0.082331</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>industryphy</td>\n      <td>0.079328</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>enttypeitem</td>\n      <td>0.064778</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>enttypeminu</td>\n      <td>0.057838</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 126
    }
   ],
   "source": [
    "\n",
    "rf_feature_importances.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'bucket_regcap', 'enttypegb', 'bucket_regcap_reccap', 'empnum', 'townsign', 'FORINVESTSIGN', 'enttypeitem', 'industryphy_industryco', 'industryphy', 'bucket_reccap', 'industryco', 'nan_num', 'orgid', 'bucket_nan_num', 'regcap', 'enttypeminu', 'enttype', 'EMPNUM', 'jobid', 'reccap', 'parnum', 'oplocdistrict', 'regcap_reccap', 'exenum'}\n"
     ]
    }
   ],
   "source": [
    "topk_feature_names = []\n",
    "topk_feature_names.extend(list(cat_feature_importances['column'].values[:20]))\n",
    "topk_feature_names.extend(list(rf_feature_importances['column'].values[:20]))\n",
    "topk_feature_names = set(topk_feature_names)\n",
    "print(topk_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'EMPNUM',\n",
       " 'FORINVESTSIGN',\n",
       " 'bucket_nan_num',\n",
       " 'bucket_reccap',\n",
       " 'bucket_regcap',\n",
       " 'bucket_regcap_reccap',\n",
       " 'empnum',\n",
       " 'enttype',\n",
       " 'enttypegb',\n",
       " 'enttypegb_enttypeitem',\n",
       " 'enttypeitem',\n",
       " 'enttypeminu',\n",
       " 'exenum',\n",
       " 'industryco',\n",
       " 'industryphy',\n",
       " 'industryphy_industryco',\n",
       " 'jobid',\n",
       " 'nan_num',\n",
       " 'oplocdistrict',\n",
       " 'orgid',\n",
       " 'parnum',\n",
       " 'reccap',\n",
       " 'regcap',\n",
       " 'regcap_reccap',\n",
       " 'townsign'}"
      ]
     },
     "metadata": {},
     "execution_count": 118
    }
   ],
   "source": [
    "topk_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features=['industryphy','opform','oploc','bucket_regcap',\n",
    "              'bucket_reccap','bucket_regcap_reccap',\n",
    "              'enttypegb','enttypeitem','enttypegb_enttypeitem',\n",
    "              'industryphy','industryco','industryphy_industryco',\n",
    "              'adbusign','townsign','regtype','TAX_CATEGORIES'\n",
    "             ]\n",
    "\n",
    "cat_features = topk_feature_names.intersection(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'bucket_reccap',\n",
       " 'bucket_regcap',\n",
       " 'bucket_regcap_reccap',\n",
       " 'enttypegb',\n",
       " 'enttypeitem',\n",
       " 'industryco',\n",
       " 'industryphy',\n",
       " 'industryphy_industryco',\n",
       " 'townsign'}"
      ]
     },
     "metadata": {},
     "execution_count": 129
    }
   ],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "model = RandomForestClassifier(max_depth=13, min_samples_split=6, n_estimators=60,\n",
      "                       oob_score=True, random_state=2020) 第1次验证的f1:0.8486352357320099\n",
      "model = RandomForestClassifier(max_depth=13, min_samples_split=6, n_estimators=60,\n",
      "                       oob_score=True, random_state=2020) 第2次验证的f1:0.7979274611398963\n",
      "model = RandomForestClassifier(max_depth=13, min_samples_split=6, n_estimators=60,\n",
      "                       oob_score=True, random_state=2020) 第3次验证的f1:0.8407960199004973\n",
      "model = RandomForestClassifier(max_depth=13, min_samples_split=6, n_estimators=60,\n",
      "                       oob_score=True, random_state=2020) 第4次验证的f1:0.8354430379746836\n",
      "model = RandomForestClassifier(max_depth=13, min_samples_split=6, n_estimators=60,\n",
      "                       oob_score=True, random_state=2020) 第5次验证的f1:0.8168316831683168\n",
      "mean f1: 0.8279266875830809\n",
      "model = <catboost.core.CatBoostClassifier object at 0x1a27d18e50> 第1次验证的f1:0.8535980148883374\n",
      "model = <catboost.core.CatBoostClassifier object at 0x1a27d18e50> 第2次验证的f1:0.8098765432098767\n",
      "model = <catboost.core.CatBoostClassifier object at 0x1a27d18e50> 第3次验证的f1:0.8550368550368549\n",
      "model = <catboost.core.CatBoostClassifier object at 0x1a27d18e50> 第4次验证的f1:0.84\n",
      "model = <catboost.core.CatBoostClassifier object at 0x1a27d18e50> 第5次验证的f1:0.8350000000000001\n",
      "mean f1: 0.8387022826270139\n"
     ]
    }
   ],
   "source": [
    "rf_score,rf_feature_importances = predict(rf,train_data[topk_feature_names],kind,test_data[topk_feature_names])\n",
    "clf=cab.CatBoostClassifier(iterations=69\n",
    "                              ,learning_rate=0.050\n",
    "                              ,depth=8\n",
    "                              ,silent=True\n",
    "                              ,thread_count=8\n",
    "                              ,task_type='CPU'\n",
    "                              ,cat_features=cat_features\n",
    "                              )\n",
    "cat_score,cat_feature_importances = predict(clf,train_data[topk_feature_names],kind,test_data[topk_feature_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "merge_score = (rf_score + cat_score)/2.0\n",
    "test_df['score'] = merge_score #可选:fina_persudo是伪标签的预测结果\n",
    "submit_csv=test_df[['id','score']]\n",
    "submit_csv.to_csv('merge_submit.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('ml': conda)",
   "display_name": "Python 3.7.9 64-bit ('ml': conda)",
   "metadata": {
    "interpreter": {
     "hash": "ad5ad074276989c7bb430cb03009529396ebc1f412808063235dd1e7fed6dc18"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}