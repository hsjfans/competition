{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Lightgbm Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross category\n",
    "def cross_category(cat_cols,data,col1,col2):\n",
    "    column = f'{col1}_{col2}'\n",
    "    new_cate = []\n",
    "    for cat1,cat2 in zip(data[col1].values,data[col2].values):\n",
    "        new_cate.append(f'{cat1}_{cat2}')\n",
    "    data[column] = new_cate\n",
    "    cat_cols.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_features = []\n",
    "cat_features = []"
   ]
  },
  {
   "source": [
    "## BaseLine Data Handle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_info = pd.read_csv('./data/train/base_info.csv')\n",
    "# 把缺失数量作为一种编码\n",
    "base_info_clean = base_info\n",
    "base_info_clean['nan_num'] = base_info.isnull().sum(axis=1)\n",
    "\n",
    "nums, shapes = base_info_clean.shape\n",
    "# 删除缺失 70%以上的数据\n",
    "for name, count in base_info_clean.isnull().sum().items():\n",
    "    if count * 1.0 / nums >= 0.70:\n",
    "        base_info_clean.drop([name], axis=1, inplace=True)\n",
    "\n",
    "# 删除类别相同的数据\n",
    "for name, count in base_info_clean.nunique().items():\n",
    "    if count == 0:\n",
    "        base_info_clean.drop([name], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0    纳米新材料、机械设备、五金配件加工、销售及技术推广服务，道路货物运输。（依法须经批准的项目，...\n1                    健身服务。（依法须经批准的项目，经相关部门批准后方可开展经营活动）\nName: opscope, dtype: object\n"
     ]
    }
   ],
   "source": [
    "base_info_clean.drop('dom',axis=1,inplace=True)\n",
    "# 正则化分词，先去除掉括号里面的内容\n",
    "print(base_info_clean['opscope'].head(2))\n",
    "opscope = base_info_clean['opscope']\n",
    "opscope.str.split(r',|、|。|;|，',expand = True).head(2)\n",
    "# 这一行先删掉，还没想好怎么处理,感觉与类别强相关\n",
    "base_info_clean.drop('opscope',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 73.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# 处理日期类\n",
    "date_cols = ['opfrom','opto']\n",
    "for col in tqdm(date_cols):\n",
    "    base_info_clean[f'{col}_year'] = pd.to_datetime(base_info[col]).dt.year.fillna(-1)\n",
    "base_info_clean['dt'] = base_info_clean['opto_year'] -  base_info_clean['opfrom_year']\n",
    "base_info_clean['dt'] = np.maximum(base_info_clean['dt'].values,-1)\n",
    "base_info_clean.drop(date_cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  4.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# 处理 category 类\n",
    "base_info_clean['opform'] = base_info_clean['opform'].replace('01', '01-以个人财产出资').replace('02', '02-以家庭共有财产作为个人出资')\n",
    "\n",
    "cat_cols = ['oplocdistrict','industryphy','industryco','enttype','enttypeitem',\n",
    "              'state','orgid','jobid',\n",
    "              'adbusign','townsign','regtype',\n",
    "              'compform','opform','venind','oploc','enttypegb']\n",
    "\n",
    "cat_len = len(cat_cols)\n",
    "for i in tqdm(range(cat_len)):\n",
    "    for j in range(i+1,cat_len,1):\n",
    "        # 类别交叉\n",
    "        cross_category(cat_cols,base_info_clean,cat_cols[i],cat_cols[j])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 136/136 [00:03<00:00, 39.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# 类别编码\n",
    "for cat_col in tqdm(cat_cols):\n",
    "    base_info_clean[cat_col] = base_info_clean[cat_col].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nan_num 分桶完毕 ......... \n"
     ]
    }
   ],
   "source": [
    "# 数值数据进行分桶处理\n",
    "\n",
    "# 对于 nan_num 采用\n",
    "# base_info_clean = base_info_clean.sort_values(by='nan_num',ascending=False)\n",
    "# 手动分箱 {7, 8, 9, 10, 11, 12, 13, 14, 15, 16}\n",
    "# <= 9, <= 11, 12, 13, >= 14\n",
    "base_info_clean['nan_num_bin'] = 1\n",
    "base_info_clean.loc[base_info_clean['nan_num'] > 9,'nan_num_bin'] = 2\n",
    "base_info_clean.loc[base_info_clean['nan_num'] >= 11,'nan_num_bin'] = 3\n",
    "base_info_clean.loc[base_info_clean['nan_num'] >= 12,'nan_num_bin'] = 4\n",
    "base_info_clean.loc[base_info_clean['nan_num'] >= 13,'nan_num_bin'] = 5\n",
    "base_info_clean.loc[base_info_clean['nan_num'] >= 14,'nan_num_bin'] = 6\n",
    "cat_cols.append('nan_num_bin')\n",
    "print(\"nan_num 分桶完毕 ......... \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "注册资本 regcap_bin 分桶完毕 ......... \n"
     ]
    }
   ],
   "source": [
    "#注册资本分桶\n",
    "base_info_clean['regcap']=base_info_clean['regcap'].fillna(base_info_clean['regcap'].median())\n",
    "base_info_clean = base_info_clean.sort_values(by='regcap')\n",
    "base_info_clean['regcap_bin']=pd.qcut(base_info_clean['regcap'],6,labels = False)\n",
    "cat_cols.append('regcap_bin')\n",
    "print(\"注册资本 regcap_bin 分桶完毕 ......... \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "empnum_bin 分桶完毕 ......... \n"
     ]
    }
   ],
   "source": [
    "# empnum 分桶\n",
    "base_info_clean['empnum']=base_info_clean['empnum'].fillna(base_info_clean['empnum'].median())\n",
    "base_info_clean = base_info_clean.sort_values(by='empnum')\n",
    "base_info_clean['empnum_bin']=pd.cut(base_info_clean['empnum'],4,labels = False)\n",
    "cat_cols.append('empnum_bin')\n",
    "print(\"empnum_bin 分桶完毕 ......... \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dt_bin 分桶完毕 ......... \n"
     ]
    }
   ],
   "source": [
    "# dt split bin\n",
    "base_info_clean['dt_bin'] = 1\n",
    "base_info_clean.loc[base_info_clean['dt'] >= 0,'dt_bin'] = 2\n",
    "base_info_clean.loc[base_info_clean['dt'] >= 30,'dt_bin'] = 3\n",
    "base_info_clean.loc[base_info_clean['dt'] >= 50,'dt_bin'] = 4\n",
    "base_info_clean.loc[base_info_clean['dt'] > 50,'dt_bin'] = 5\n",
    "cat_cols.append('dt_bin')\n",
    "print(\"dt_bin 分桶完毕 ......... \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_features.append(base_info_clean)\n",
    "cat_features.extend(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " baseline handle finish --------\n"
     ]
    }
   ],
   "source": [
    "print(' baseline handle finish --------')"
   ]
  },
  {
   "source": [
    "## annual_report_info data handle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_report_info=pd.read_csv('./data/train/annual_report_info.csv')#企业的年报基本信息\n",
    "count, shapes = annual_report_info.shape\n",
    "#空值大于0.7的列都删除掉\n",
    "annual_report_info_clean=annual_report_info.dropna(thresh=annual_report_info.shape[0]*0.7,how='all',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   EMPNUM  COLGRANUM  RETSOLNUM  DISPERNUM  UNENUM  COLEMPLNUM  RETEMPLNUM  \\\n",
       "0    10.0        0.0        0.0        0.0     0.0         0.0         0.0   \n",
       "1     2.0        0.0        0.0        0.0     0.0         0.0         0.0   \n",
       "2     4.0        3.0        0.0        0.0     0.0         1.0         0.0   \n",
       "3     3.0        1.0        0.0        0.0     0.0         2.0         0.0   \n",
       "4    10.0        0.0        0.0        0.0     0.0         0.0         0.0   \n",
       "\n",
       "   DISEMPLNUM  UNEEMPLNUM  \n",
       "0         0.0         0.0  \n",
       "1         0.0         0.0  \n",
       "2         0.0         0.0  \n",
       "3         0.0         0.0  \n",
       "4         0.0         0.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EMPNUM</th>\n      <th>COLGRANUM</th>\n      <th>RETSOLNUM</th>\n      <th>DISPERNUM</th>\n      <th>UNENUM</th>\n      <th>COLEMPLNUM</th>\n      <th>RETEMPLNUM</th>\n      <th>DISEMPLNUM</th>\n      <th>UNEEMPLNUM</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 324
    }
   ],
   "source": [
    "# 人数的信息\n",
    "num_cols = ['EMPNUM','COLGRANUM','RETSOLNUM','DISPERNUM','UNENUM','COLEMPLNUM','RETEMPLNUM','DISEMPLNUM','UNEEMPLNUM']\n",
    "annual_report_info_clean[num_cols] = annual_report_info_clean[num_cols].fillna(-1,axis = 1)\n",
    "annual_report_info_clean[num_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 765.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# delete 0 and -1 >= 0.8\n",
    "for num_col in tqdm(num_cols):\n",
    "    num  = (annual_report_info_clean[num_col].values <= 0).sum()\n",
    "    if num*1.0/count >= 0.8:\n",
    "        annual_report_info_clean.drop(num_col,axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   COLEMPLNUM  COLGRANUM  EMPNUM\n",
       "0         0.0        0.0    10.0\n",
       "1         0.0        0.0     2.0\n",
       "2         1.0        3.0     4.0\n",
       "3         2.0        1.0     3.0\n",
       "4         0.0        0.0    10.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>COLEMPLNUM</th>\n      <th>COLGRANUM</th>\n      <th>EMPNUM</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>10.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 326
    }
   ],
   "source": [
    "num_cols = list(set(num_cols) & set(annual_report_info_clean.columns))\n",
    "annual_report_info_clean[num_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 8937/8937 [00:05<00:00, 1699.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# category 类别进行编码\n",
    "cat_cols = ['STATE','EMPNUMSIGN','BUSSTNAME','FORINVESTSIGN','WEBSITSIGN','FORINVESTSIGN','PUBSTATE']\n",
    "# 类别信息 取最新非nan数据\n",
    "# 雇佣人数，取均值，增量，\n",
    "grouped = annual_report_info_clean.sort_values(by='ANCHEYEAR',ascending= False).groupby('id')\n",
    "clean_infos = []\n",
    "for name, group_info in tqdm(grouped):\n",
    "     clean_info = {'id':name}\n",
    "     clean_info['ANCHEYEAR'] = group_info['ANCHEYEAR'].values[-1]\n",
    "     clean_info['ANCHEYEAR_DT'] = group_info['ANCHEYEAR'].values[-1] - group_info['ANCHEYEAR'].values[0]\n",
    "     clean_info['REPORT_NUM'] = len(group_info) \n",
    "     clean_info['HAS_REPORT'] = 1.0\n",
    "     for cat_col in cat_cols:\n",
    "         clean_info[cat_col] = group_info[cat_col].values[-1]\n",
    "     for num_col in num_cols:\n",
    "         clean_info[f'{num_col}'] = group_info[num_col].values[-1]\n",
    "         clean_info[f'{num_col}_MEAN'] = group_info[num_col].values.mean()\n",
    "         clean_info[f'{num_col}_ADD'] = 0.0\n",
    "         if len(group_info) > 1:\n",
    "             clean_info[f'{num_col}_ADD'] = group_info[num_col].values[-1] - group_info[num_col].values[-2]     \n",
    "     clean_infos.append(clean_info)\n",
    "annual_report_info_clean = pd.DataFrame(clean_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 154.88it/s]COLEMPLNUM 分桶完毕 ......... \n",
      "COLGRANUM 分桶完毕 ......... \n",
      "EMPNUM 分桶完毕 ......... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# num split bin\n",
    "# num_cols 分桶\n",
    "for num_col in tqdm(num_cols):\n",
    "    annual_report_info_clean[num_col]=annual_report_info_clean[num_col].fillna(annual_report_info_clean[num_col].median())\n",
    "    annual_report_info_clean = annual_report_info_clean.sort_values(by=num_col)\n",
    "    annual_report_info_clean[f'{num_col}_bin']=pd.cut(annual_report_info_clean[num_col],3,labels = False)\n",
    "    cat_cols.append(f'{num_col}_bin')   \n",
    "    print(f\"{num_col} 分桶完毕 ......... \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "annual_report_info_clean handle end ......... \n"
     ]
    }
   ],
   "source": [
    "cat_features.extend(cat_cols)\n",
    "clean_features.append(annual_report_info_clean)\n",
    "print(\"annual_report_info_clean handle end ......... \")"
   ]
  },
  {
   "source": [
    "## tax_info data handle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_info = pd.read_csv('./data/train/tax_info.csv')\n",
    "count, shapes = tax_info.shape\n",
    "#空值大于0.7的列都删除掉\n",
    "tax_info_clean=tax_info.dropna(thresh= count*0.7,how='all',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 808/808 [00:00<00:00, 3414.62it/s]\n"
     ]
    }
   ],
   "source": [
    "groups = tax_info_clean.groupby('id')\n",
    "tax_cleans = []\n",
    "tax_cols = ['TAX_AMOUNT']\n",
    "for name, group_info in tqdm(groups):\n",
    "    tax_clean ={'id':name}\n",
    "    tax_clean['TAX_NUM'] = len(group_info)\n",
    "    tax_clean['HAS_TAX'] = 1.0\n",
    "    for tax_col in tax_cols:\n",
    "        tax_clean[f'{tax_col}_MEAN'] = group_info[tax_col].dropna().values.mean()\n",
    "    tax_cleans.append(tax_clean)\n",
    "tax_info_clean = pd.DataFrame(tax_cleans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tax_info_clean handle end ......... \n"
     ]
    }
   ],
   "source": [
    "clean_features.append(tax_info_clean)\n",
    "cat_features.append('HAS_TAX')\n",
    "print(\"tax_info_clean handle end ......... \")"
   ]
  },
  {
   "source": [
    "## news_info data handle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_info = pd.read_csv('./data/train/news_info.csv')\n",
    "count, shape = news_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_info['public_date'] = news_info['public_date'].replace('\\d+\\D+前$','2020-10-01',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0     2016-12-30\n",
       "1     2017-08-09\n",
       "2     2016-02-29\n",
       "3     2018-06-08\n",
       "4     2015-06-29\n",
       "5     2015-06-15\n",
       "6     2019-10-26\n",
       "7     2017-11-01\n",
       "8     2018-04-20\n",
       "9     2018-01-08\n",
       "10    2017-12-14\n",
       "11    2015-05-12\n",
       "12    2017-11-28\n",
       "13    2016-10-17\n",
       "14    2019-03-29\n",
       "15    2019-04-18\n",
       "16    2018-04-11\n",
       "17    2016-07-14\n",
       "18    2018-04-02\n",
       "19    2016-07-20\n",
       "Name: public_date, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 335
    }
   ],
   "source": [
    "news_info['public_date'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 927/927 [00:00<00:00, 2674.55it/s]\n"
     ]
    }
   ],
   "source": [
    "news_info['positive_negtive'] = news_info['positive_negtive'].fillna('-1')\n",
    "news_info['public_date_year'] = pd.to_datetime(news_info['public_date']).dt.year.fillna(-1)\n",
    "groups = news_info.sort_values(by = 'public_date_year',ascending= False).groupby('id')\n",
    "# 最近的情感色彩，以及最多的情感色彩 和次数，缺失默认为-1\n",
    "code_map = {'中立':2,'消极':1,'积极':3,'-1':-1}\n",
    "news_info_cleans = []\n",
    "for name, group in tqdm(groups):\n",
    "    news_info_clean = {'id':name}\n",
    "    news_info_clean['public_date_year'] = group['public_date_year'].values[0]\n",
    "    news_info_clean['public_date_year_dt'] = group['public_date_year'].values[0] - group['public_date_year'].values[-1]\n",
    "    news_info_clean['positive_negtive_mode'] = group['positive_negtive'].mode().values[0]\n",
    "    news_info_clean['positive_negtive_last'] = group['positive_negtive'].values[0]\n",
    "    news_info_clean['positive_negtive_num'] = len(group)\n",
    "    news_info_clean['has_news_info'] = 1.0\n",
    "    news_info_cleans.append(news_info_clean)\n",
    "news_info_clean = pd.DataFrame(news_info_cleans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features.append('has_news_info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                 id  public_date_year  \\\n",
       "0  09912c34159b1720558a419983a989f1dd2e0ed69a044ca3              2016   \n",
       "1  175ebe5f059ec050afbd65251ecdd3b512bfbe5e62d041b0              2020   \n",
       "2  216bd2aaf4d079240c3ac0b76f0ef4aa355d443880ba78db              2020   \n",
       "3  216bd2aaf4d079240f5823e63d24b44dd2c58e3281b822f6              2020   \n",
       "4  216bd2aaf4d0792410725ba5e7ca1dc32ce55767372f2030              2014   \n",
       "\n",
       "   public_date_year_dt positive_negtive_mode positive_negtive_last  \\\n",
       "0                    0                    中立                    中立   \n",
       "1                    3                    积极                    中立   \n",
       "2                    0                    积极                    积极   \n",
       "3                    0                    中立                    中立   \n",
       "4                    0                    消极                    消极   \n",
       "\n",
       "   positive_negtive_num  has_news_info  \n",
       "0                     6            1.0  \n",
       "1                     7            1.0  \n",
       "2                     3            1.0  \n",
       "3                     2            1.0  \n",
       "4                     1            1.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>public_date_year</th>\n      <th>public_date_year_dt</th>\n      <th>positive_negtive_mode</th>\n      <th>positive_negtive_last</th>\n      <th>positive_negtive_num</th>\n      <th>has_news_info</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>09912c34159b1720558a419983a989f1dd2e0ed69a044ca3</td>\n      <td>2016</td>\n      <td>0</td>\n      <td>中立</td>\n      <td>中立</td>\n      <td>6</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>175ebe5f059ec050afbd65251ecdd3b512bfbe5e62d041b0</td>\n      <td>2020</td>\n      <td>3</td>\n      <td>积极</td>\n      <td>中立</td>\n      <td>7</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>216bd2aaf4d079240c3ac0b76f0ef4aa355d443880ba78db</td>\n      <td>2020</td>\n      <td>0</td>\n      <td>积极</td>\n      <td>积极</td>\n      <td>3</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>216bd2aaf4d079240f5823e63d24b44dd2c58e3281b822f6</td>\n      <td>2020</td>\n      <td>0</td>\n      <td>中立</td>\n      <td>中立</td>\n      <td>2</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>216bd2aaf4d0792410725ba5e7ca1dc32ce55767372f2030</td>\n      <td>2014</td>\n      <td>0</td>\n      <td>消极</td>\n      <td>消极</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 338
    }
   ],
   "source": [
    "news_info_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "news_info_clean handle end ......... \n"
     ]
    }
   ],
   "source": [
    "clean_features.append(news_info_clean)\n",
    "print(\"news_info_clean handle end ......... \")"
   ]
  },
  {
   "source": [
    "## change_info data handle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_info = pd.read_csv('./data/train/change_info.csv')\n",
    "count, shape = change_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_info['bgrq'] = change_info['bgrq'].astype(str).str[0:4].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 8726/8726 [00:01<00:00, 5661.62it/s]\n"
     ]
    }
   ],
   "source": [
    "groups = change_info.sort_values(by='bgrq',ascending= False).groupby('id')\n",
    "change_info_cleans = []\n",
    "for name, group in tqdm(groups):\n",
    "    change_info_clean = {}\n",
    "    change_info_clean['id'] = name\n",
    "    change_info_clean['has_change_info'] = 1.0\n",
    "    change_info_clean['bgxmdm'] = group['bgxmdm'].values[0]\n",
    "    change_info_clean['bgrq'] = group['bgrq'].values[0]\n",
    "    change_info_cleans.append(change_info_clean)\n",
    "change_info_clean = pd.DataFrame(change_info_cleans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features.append('has_change_info')\n",
    "cat_features.append('bgxmdm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       has_change_info       bgxmdm         bgrq\n",
       "count           8726.0  8726.000000  8726.000000\n",
       "mean               1.0   175.499312  2017.816984\n",
       "std                0.0   207.917334     2.169936\n",
       "min                1.0   110.000000  1999.000000\n",
       "25%                1.0   112.000000  2017.000000\n",
       "50%                1.0   113.000000  2018.000000\n",
       "75%                1.0   121.000000  2019.000000\n",
       "max                1.0   939.000000  2020.000000"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>has_change_info</th>\n      <th>bgxmdm</th>\n      <th>bgrq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>8726.0</td>\n      <td>8726.000000</td>\n      <td>8726.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.0</td>\n      <td>175.499312</td>\n      <td>2017.816984</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.0</td>\n      <td>207.917334</td>\n      <td>2.169936</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.0</td>\n      <td>110.000000</td>\n      <td>1999.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.0</td>\n      <td>112.000000</td>\n      <td>2017.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.0</td>\n      <td>113.000000</td>\n      <td>2018.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.0</td>\n      <td>121.000000</td>\n      <td>2019.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.0</td>\n      <td>939.000000</td>\n      <td>2020.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 344
    }
   ],
   "source": [
    "change_info_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "change_info_clean handle end ......... \n"
     ]
    }
   ],
   "source": [
    "clean_features.append(change_info_clean)\n",
    "print(\"change_info_clean handle end ......... \")"
   ]
  },
  {
   "source": [
    "## Other_info data handle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(id                    1888\n",
       " legal_judgment_num      93\n",
       " brand_num               82\n",
       " patent_num             114\n",
       " dtype: int64,\n",
       " 1890)"
      ]
     },
     "metadata": {},
     "execution_count": 346
    }
   ],
   "source": [
    "\n",
    "other_info = pd.read_csv('./data/train/other_info.csv')\n",
    "count, shape = other_info.shape\n",
    "other_info.nunique(),count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_info_clean=other_info.dropna(thresh= count*0.5,how='all',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1888/1888 [00:00<00:00, 2792.45it/s]\n"
     ]
    }
   ],
   "source": [
    "groups = other_info_clean.groupby('id')\n",
    "other_info_cleans = []\n",
    "for name, group in tqdm(groups):\n",
    "    other_info_clean = {'id':name}\n",
    "    other_info_clean['has_other_info'] = 1.0\n",
    "    other_info_clean['legal_judgment_num'] = group['legal_judgment_num'].sum()\n",
    "    other_info_clean['has_legal_judgment'] = int(len(group['legal_judgment_num'].dropna()) > 0)\n",
    "    other_info_cleans.append(other_info_clean)\n",
    "other_info_clean = pd.DataFrame(other_info_cleans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features.append('has_other_info')\n",
    "cat_features.append('has_legal_judgment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1888 entries, 0 to 1887\nData columns (total 4 columns):\n #   Column              Non-Null Count  Dtype  \n---  ------              --------------  -----  \n 0   id                  1888 non-null   object \n 1   has_other_info      1888 non-null   float64\n 2   legal_judgment_num  1888 non-null   float64\n 3   has_legal_judgment  1888 non-null   int64  \ndtypes: float64(2), int64(1), object(1)\nmemory usage: 59.1+ KB\n"
     ]
    }
   ],
   "source": [
    "other_info_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "other_info_clean handle end ......... \n"
     ]
    }
   ],
   "source": [
    "clean_features.append(other_info_clean)\n",
    "print(\"other_info_clean handle end ......... \")"
   ]
  },
  {
   "source": [
    "## Merhe features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                 id  oplocdistrict  \\\n",
       "0  82750f1b9d1223507d25fecaca05aec1cfdf7ceb97a535f1              1   \n",
       "1  f000950527a6feb6a005c09bbd2e2696880df8cd9b350ae2              1   \n",
       "2  f000950527a6feb6ff31ae2cda4757703f52e853bb38b67e              1   \n",
       "3  47645761dc56bb8cabcff709f67c168821d276310d6e5210             10   \n",
       "4  516ab81418ed215dcd9df1915f3a2ae8098e3589b042ee45             12   \n",
       "\n",
       "   industryphy  industryco  enttype  enttypeitem  state  orgid  jobid  \\\n",
       "0           14         244        0            2      1     40    156   \n",
       "1           14         246        0            2      1     30    137   \n",
       "2           17         318        0            2      2     32    201   \n",
       "3           10         138        0            5      1     62    124   \n",
       "4           17         329        9           18      1     70    280   \n",
       "\n",
       "   adbusign  ...  positive_negtive_mode  positive_negtive_last  \\\n",
       "0         0  ...                    NaN                    NaN   \n",
       "1         0  ...                    NaN                    NaN   \n",
       "2         0  ...                    NaN                    NaN   \n",
       "3         0  ...                    NaN                    NaN   \n",
       "4         0  ...                    NaN                    NaN   \n",
       "\n",
       "   positive_negtive_num  has_news_info  has_change_info  bgxmdm    bgrq  \\\n",
       "0                   NaN            NaN              NaN     NaN     NaN   \n",
       "1                   NaN            NaN              1.0   115.0  2020.0   \n",
       "2                   NaN            NaN              1.0   115.0  2013.0   \n",
       "3                   NaN            NaN              1.0   113.0  2014.0   \n",
       "4                   NaN            NaN              1.0   128.0  2015.0   \n",
       "\n",
       "   has_other_info  legal_judgment_num  has_legal_judgment  \n",
       "0             NaN                 NaN                 NaN  \n",
       "1             1.0                 1.0                 1.0  \n",
       "2             NaN                 NaN                 NaN  \n",
       "3             NaN                 NaN                 NaN  \n",
       "4             NaN                 NaN                 NaN  \n",
       "\n",
       "[5 rows x 184 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>oplocdistrict</th>\n      <th>industryphy</th>\n      <th>industryco</th>\n      <th>enttype</th>\n      <th>enttypeitem</th>\n      <th>state</th>\n      <th>orgid</th>\n      <th>jobid</th>\n      <th>adbusign</th>\n      <th>...</th>\n      <th>positive_negtive_mode</th>\n      <th>positive_negtive_last</th>\n      <th>positive_negtive_num</th>\n      <th>has_news_info</th>\n      <th>has_change_info</th>\n      <th>bgxmdm</th>\n      <th>bgrq</th>\n      <th>has_other_info</th>\n      <th>legal_judgment_num</th>\n      <th>has_legal_judgment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>82750f1b9d1223507d25fecaca05aec1cfdf7ceb97a535f1</td>\n      <td>1</td>\n      <td>14</td>\n      <td>244</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>40</td>\n      <td>156</td>\n      <td>0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>f000950527a6feb6a005c09bbd2e2696880df8cd9b350ae2</td>\n      <td>1</td>\n      <td>14</td>\n      <td>246</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>30</td>\n      <td>137</td>\n      <td>0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>115.0</td>\n      <td>2020.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>f000950527a6feb6ff31ae2cda4757703f52e853bb38b67e</td>\n      <td>1</td>\n      <td>17</td>\n      <td>318</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>32</td>\n      <td>201</td>\n      <td>0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>115.0</td>\n      <td>2013.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>47645761dc56bb8cabcff709f67c168821d276310d6e5210</td>\n      <td>10</td>\n      <td>10</td>\n      <td>138</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>62</td>\n      <td>124</td>\n      <td>0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>113.0</td>\n      <td>2014.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>516ab81418ed215dcd9df1915f3a2ae8098e3589b042ee45</td>\n      <td>12</td>\n      <td>17</td>\n      <td>329</td>\n      <td>9</td>\n      <td>18</td>\n      <td>1</td>\n      <td>70</td>\n      <td>280</td>\n      <td>0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>128.0</td>\n      <td>2015.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 184 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 352
    }
   ],
   "source": [
    "\n",
    "features = clean_features[0]\n",
    "for clean_feature in clean_features[1:]:\n",
    "    features = pd.merge(features, clean_feature, on='id',how = 'left')\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "addition_nan_num 分桶完毕 ......... \n"
     ]
    }
   ],
   "source": [
    "features['addition_nan_num'] = features.isnull().sum(axis=1)\n",
    "# 缺失值分桶\n",
    "features['addition_nan_num_bin'] = 1\n",
    "features.loc[features['addition_nan_num'] >= 8,'addition_nan_num_bin'] = 2\n",
    "features.loc[features['addition_nan_num'] >= 10,'addition_nan_num_bin'] = 3\n",
    "features.loc[features['addition_nan_num'] >= 11,'addition_nan_num_bin'] = 4\n",
    "features.loc[features['addition_nan_num'] >= 26,'addition_nan_num_bin'] = 5\n",
    "print(\"addition_nan_num 分桶完毕 ......... \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features.append('addition_nan_num_bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_cols = ['has_other_info','has_news_info','HAS_TAX','has_change_info','HAS_REPORT']\n",
    "features[has_cols] = features[has_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 208.69it/s]\n"
     ]
    }
   ],
   "source": [
    "code_map = {'中立':2,'消极':1,'积极':3,'-1':-1}\n",
    "cols = ['positive_negtive_mode','positive_negtive_last']\n",
    "features[cols] = features[cols].fillna('-1')\n",
    "for col in tqdm(cols):\n",
    "    features[col] = features[col].map(code_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['new_empnum'] = (features['empnum'] + features['EMPNUM'] + 1)/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 157/157 [00:00<00:00, 852.74it/s]\n"
     ]
    }
   ],
   "source": [
    "for cat_col in tqdm(cat_features):\n",
    "    features[cat_col] = features[cat_col].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       oplocdistrict   industryphy    industryco       enttype   enttypeitem  \\\n",
       "count   24865.000000  24865.000000  24865.000000  24865.000000  24865.000000   \n",
       "mean        5.764327     13.290690    229.647738      6.130505      4.112407   \n",
       "std         3.519292      2.166892     54.332704      7.378857      5.241884   \n",
       "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         3.000000     12.000000    199.000000      0.000000      0.000000   \n",
       "50%         6.000000     14.000000    238.000000      0.000000      3.000000   \n",
       "75%         8.000000     14.000000    260.000000     16.000000      5.000000   \n",
       "max        15.000000     19.000000    345.000000     16.000000     31.000000   \n",
       "\n",
       "              state         orgid         jobid      adbusign      townsign  \\\n",
       "count  24865.000000  24865.000000  24865.000000  24865.000000  24865.000000   \n",
       "mean       1.141283     32.801689    196.977760      0.002815      0.578444   \n",
       "std        0.382233     18.623124    127.305216      0.052985      0.493818   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        1.000000     18.000000     89.000000      0.000000      0.000000   \n",
       "50%        1.000000     32.000000    162.000000      0.000000      1.000000   \n",
       "75%        1.000000     44.000000    323.000000      0.000000      1.000000   \n",
       "max        5.000000     77.000000    433.000000      1.000000      1.000000   \n",
       "\n",
       "       ...  has_news_info  has_change_info        bgxmdm          bgrq  \\\n",
       "count  ...   24865.000000     24865.000000  24865.000000  24865.000000   \n",
       "mean   ...       0.037281         0.350935      2.930263    707.473638   \n",
       "std    ...       0.189454         0.477272      6.443869    963.526183   \n",
       "min    ...       0.000000         0.000000      0.000000     -1.000000   \n",
       "25%    ...       0.000000         0.000000      0.000000     -1.000000   \n",
       "50%    ...       0.000000         0.000000      0.000000     -1.000000   \n",
       "75%    ...       0.000000         1.000000      4.000000   2017.000000   \n",
       "max    ...       1.000000         1.000000     35.000000   2020.000000   \n",
       "\n",
       "       has_other_info  legal_judgment_num  has_legal_judgment  \\\n",
       "count    24865.000000        24865.000000        24865.000000   \n",
       "mean         0.075930           -0.325317            0.116308   \n",
       "std          0.264891           11.407953            0.428420   \n",
       "min          0.000000           -1.000000            0.000000   \n",
       "25%          0.000000           -1.000000            0.000000   \n",
       "50%          0.000000           -1.000000            0.000000   \n",
       "75%          0.000000           -1.000000            0.000000   \n",
       "max          1.000000          959.000000            2.000000   \n",
       "\n",
       "       addition_nan_num  addition_nan_num_bin    new_empnum  \n",
       "count       24865.00000          24865.000000  24865.000000  \n",
       "mean           27.81118              3.492821      3.736014  \n",
       "std            11.19453              0.865490     19.400637  \n",
       "min             0.00000              0.000000      0.000000  \n",
       "25%            15.00000              3.000000      1.500000  \n",
       "50%            34.00000              4.000000      2.000000  \n",
       "75%            37.00000              4.000000      3.500000  \n",
       "max            37.00000              4.000000   1296.500000  \n",
       "\n",
       "[8 rows x 186 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>oplocdistrict</th>\n      <th>industryphy</th>\n      <th>industryco</th>\n      <th>enttype</th>\n      <th>enttypeitem</th>\n      <th>state</th>\n      <th>orgid</th>\n      <th>jobid</th>\n      <th>adbusign</th>\n      <th>townsign</th>\n      <th>...</th>\n      <th>has_news_info</th>\n      <th>has_change_info</th>\n      <th>bgxmdm</th>\n      <th>bgrq</th>\n      <th>has_other_info</th>\n      <th>legal_judgment_num</th>\n      <th>has_legal_judgment</th>\n      <th>addition_nan_num</th>\n      <th>addition_nan_num_bin</th>\n      <th>new_empnum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>24865.000000</td>\n      <td>24865.000000</td>\n      <td>24865.000000</td>\n      <td>24865.000000</td>\n      <td>24865.000000</td>\n      <td>24865.000000</td>\n      <td>24865.000000</td>\n      <td>24865.000000</td>\n      <td>24865.000000</td>\n      <td>24865.000000</td>\n      <td>...</td>\n      <td>24865.000000</td>\n      <td>24865.000000</td>\n      <td>24865.000000</td>\n      <td>24865.000000</td>\n      <td>24865.000000</td>\n      <td>24865.000000</td>\n      <td>24865.000000</td>\n      <td>24865.00000</td>\n      <td>24865.000000</td>\n      <td>24865.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5.764327</td>\n      <td>13.290690</td>\n      <td>229.647738</td>\n      <td>6.130505</td>\n      <td>4.112407</td>\n      <td>1.141283</td>\n      <td>32.801689</td>\n      <td>196.977760</td>\n      <td>0.002815</td>\n      <td>0.578444</td>\n      <td>...</td>\n      <td>0.037281</td>\n      <td>0.350935</td>\n      <td>2.930263</td>\n      <td>707.473638</td>\n      <td>0.075930</td>\n      <td>-0.325317</td>\n      <td>0.116308</td>\n      <td>27.81118</td>\n      <td>3.492821</td>\n      <td>3.736014</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.519292</td>\n      <td>2.166892</td>\n      <td>54.332704</td>\n      <td>7.378857</td>\n      <td>5.241884</td>\n      <td>0.382233</td>\n      <td>18.623124</td>\n      <td>127.305216</td>\n      <td>0.052985</td>\n      <td>0.493818</td>\n      <td>...</td>\n      <td>0.189454</td>\n      <td>0.477272</td>\n      <td>6.443869</td>\n      <td>963.526183</td>\n      <td>0.264891</td>\n      <td>11.407953</td>\n      <td>0.428420</td>\n      <td>11.19453</td>\n      <td>0.865490</td>\n      <td>19.400637</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>3.000000</td>\n      <td>12.000000</td>\n      <td>199.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>18.000000</td>\n      <td>89.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>15.00000</td>\n      <td>3.000000</td>\n      <td>1.500000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>6.000000</td>\n      <td>14.000000</td>\n      <td>238.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>32.000000</td>\n      <td>162.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>34.00000</td>\n      <td>4.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>8.000000</td>\n      <td>14.000000</td>\n      <td>260.000000</td>\n      <td>16.000000</td>\n      <td>5.000000</td>\n      <td>1.000000</td>\n      <td>44.000000</td>\n      <td>323.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>4.000000</td>\n      <td>2017.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>37.00000</td>\n      <td>4.000000</td>\n      <td>3.500000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>15.000000</td>\n      <td>19.000000</td>\n      <td>345.000000</td>\n      <td>16.000000</td>\n      <td>31.000000</td>\n      <td>5.000000</td>\n      <td>77.000000</td>\n      <td>433.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>35.000000</td>\n      <td>2020.000000</td>\n      <td>1.000000</td>\n      <td>959.000000</td>\n      <td>2.000000</td>\n      <td>37.00000</td>\n      <td>4.000000</td>\n      <td>1296.500000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 186 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 360
    }
   ],
   "source": [
    "features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv('./features/lgb_features.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "import catboost as cab\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold,GridSearchCV,ParameterGrid\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support,make_scorer\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['oplocdistrict',\n",
       " 'industryphy',\n",
       " 'industryco',\n",
       " 'enttype',\n",
       " 'enttypeitem',\n",
       " 'state',\n",
       " 'orgid',\n",
       " 'jobid',\n",
       " 'adbusign',\n",
       " 'townsign',\n",
       " 'regtype',\n",
       " 'compform',\n",
       " 'opform',\n",
       " 'venind',\n",
       " 'oploc',\n",
       " 'enttypegb',\n",
       " 'oplocdistrict_industryphy',\n",
       " 'oplocdistrict_industryco',\n",
       " 'oplocdistrict_enttype',\n",
       " 'oplocdistrict_enttypeitem',\n",
       " 'oplocdistrict_state',\n",
       " 'oplocdistrict_orgid',\n",
       " 'oplocdistrict_jobid',\n",
       " 'oplocdistrict_adbusign',\n",
       " 'oplocdistrict_townsign',\n",
       " 'oplocdistrict_regtype',\n",
       " 'oplocdistrict_compform',\n",
       " 'oplocdistrict_opform',\n",
       " 'oplocdistrict_venind',\n",
       " 'oplocdistrict_oploc',\n",
       " 'oplocdistrict_enttypegb',\n",
       " 'industryphy_industryco',\n",
       " 'industryphy_enttype',\n",
       " 'industryphy_enttypeitem',\n",
       " 'industryphy_state',\n",
       " 'industryphy_orgid',\n",
       " 'industryphy_jobid',\n",
       " 'industryphy_adbusign',\n",
       " 'industryphy_townsign',\n",
       " 'industryphy_regtype',\n",
       " 'industryphy_compform',\n",
       " 'industryphy_opform',\n",
       " 'industryphy_venind',\n",
       " 'industryphy_oploc',\n",
       " 'industryphy_enttypegb',\n",
       " 'industryco_enttype',\n",
       " 'industryco_enttypeitem',\n",
       " 'industryco_state',\n",
       " 'industryco_orgid',\n",
       " 'industryco_jobid',\n",
       " 'industryco_adbusign',\n",
       " 'industryco_townsign',\n",
       " 'industryco_regtype',\n",
       " 'industryco_compform',\n",
       " 'industryco_opform',\n",
       " 'industryco_venind',\n",
       " 'industryco_oploc',\n",
       " 'industryco_enttypegb',\n",
       " 'enttype_enttypeitem',\n",
       " 'enttype_state',\n",
       " 'enttype_orgid',\n",
       " 'enttype_jobid',\n",
       " 'enttype_adbusign',\n",
       " 'enttype_townsign',\n",
       " 'enttype_regtype',\n",
       " 'enttype_compform',\n",
       " 'enttype_opform',\n",
       " 'enttype_venind',\n",
       " 'enttype_oploc',\n",
       " 'enttype_enttypegb',\n",
       " 'enttypeitem_state',\n",
       " 'enttypeitem_orgid',\n",
       " 'enttypeitem_jobid',\n",
       " 'enttypeitem_adbusign',\n",
       " 'enttypeitem_townsign',\n",
       " 'enttypeitem_regtype',\n",
       " 'enttypeitem_compform',\n",
       " 'enttypeitem_opform',\n",
       " 'enttypeitem_venind',\n",
       " 'enttypeitem_oploc',\n",
       " 'enttypeitem_enttypegb',\n",
       " 'state_orgid',\n",
       " 'state_jobid',\n",
       " 'state_adbusign',\n",
       " 'state_townsign',\n",
       " 'state_regtype',\n",
       " 'state_compform',\n",
       " 'state_opform',\n",
       " 'state_venind',\n",
       " 'state_oploc',\n",
       " 'state_enttypegb',\n",
       " 'orgid_jobid',\n",
       " 'orgid_adbusign',\n",
       " 'orgid_townsign',\n",
       " 'orgid_regtype',\n",
       " 'orgid_compform',\n",
       " 'orgid_opform',\n",
       " 'orgid_venind',\n",
       " 'orgid_oploc',\n",
       " 'orgid_enttypegb',\n",
       " 'jobid_adbusign',\n",
       " 'jobid_townsign',\n",
       " 'jobid_regtype',\n",
       " 'jobid_compform',\n",
       " 'jobid_opform',\n",
       " 'jobid_venind',\n",
       " 'jobid_oploc',\n",
       " 'jobid_enttypegb',\n",
       " 'adbusign_townsign',\n",
       " 'adbusign_regtype',\n",
       " 'adbusign_compform',\n",
       " 'adbusign_opform',\n",
       " 'adbusign_venind',\n",
       " 'adbusign_oploc',\n",
       " 'adbusign_enttypegb',\n",
       " 'townsign_regtype',\n",
       " 'townsign_compform',\n",
       " 'townsign_opform',\n",
       " 'townsign_venind',\n",
       " 'townsign_oploc',\n",
       " 'townsign_enttypegb',\n",
       " 'regtype_compform',\n",
       " 'regtype_opform',\n",
       " 'regtype_venind',\n",
       " 'regtype_oploc',\n",
       " 'regtype_enttypegb',\n",
       " 'compform_opform',\n",
       " 'compform_venind',\n",
       " 'compform_oploc',\n",
       " 'compform_enttypegb',\n",
       " 'opform_venind',\n",
       " 'opform_oploc',\n",
       " 'opform_enttypegb',\n",
       " 'venind_oploc',\n",
       " 'venind_enttypegb',\n",
       " 'oploc_enttypegb',\n",
       " 'nan_num_bin',\n",
       " 'regcap_bin',\n",
       " 'empnum_bin',\n",
       " 'dt_bin',\n",
       " 'STATE',\n",
       " 'EMPNUMSIGN',\n",
       " 'BUSSTNAME',\n",
       " 'FORINVESTSIGN',\n",
       " 'WEBSITSIGN',\n",
       " 'FORINVESTSIGN',\n",
       " 'PUBSTATE',\n",
       " 'COLEMPLNUM_bin',\n",
       " 'COLGRANUM_bin',\n",
       " 'EMPNUM_bin',\n",
       " 'HAS_TAX',\n",
       " 'has_news_info',\n",
       " 'has_change_info',\n",
       " 'bgxmdm',\n",
       " 'has_other_info',\n",
       " 'has_legal_judgment',\n",
       " 'addition_nan_num_bin']"
      ]
     },
     "metadata": {},
     "execution_count": 377
    }
   ],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('./features/lgb_features.csv')\n",
    "entprise_info = pd.read_csv('./data/train/entprise_info.csv')\n",
    "data = pd.merge(features, entprise_info, how='left', on='id')\n",
    "data[cat_features] = data[cat_features].astype(int)\n",
    "# print(data.max())\n",
    "train = data[data.label.notna()]\n",
    "test = data[data.label.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = train.drop(\n",
    "        ['id', 'label'], axis=1), train['label']\n",
    "test_data = test.drop(\n",
    "        ['label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model, train_data, train_labels, n_splits = 5):\n",
    "    f1_scores = []\n",
    "    sk = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2022)\n",
    "    for train, test in sk.split(train_data, train_labels):\n",
    "        x_train = train_data.iloc[train]\n",
    "        y_train = train_labels.iloc[train]\n",
    "        x_valid = train_data.iloc[test]\n",
    "        y_valid = train_labels.iloc[test]\n",
    "\n",
    "        model.fit(x_train, y_train,eval_set=(x_valid, y_valid))\n",
    "        y_pred = model.predict(x_valid)\n",
    "        f1_score_k = f1_score(y_pred.round(),y_valid)\n",
    "        f1_scores.append(f1_score_k)\n",
    "    return sum(f1_scores)/n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_model(loss_function, lr, max_depth, l2_leaf_reg,cat_features):\n",
    "    clf = cab.CatBoostClassifier(iterations=200,\n",
    "                                 learning_rate=lr,\n",
    "                                 depth=max_depth,\n",
    "                                 loss_function = loss_function,\n",
    "                                 l2_leaf_reg = l2_leaf_reg,\n",
    "                                 silent=True,\n",
    "                                 thread_count=8,\n",
    "                                 task_type='GPU',\n",
    "                                 cat_features=cat_features,\n",
    "                                 early_stopping_rounds = 200,\n",
    "                                 leaf_estimation_iterations = 10,\n",
    "                                 )\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catboost_GridSearchCV(train_data, train_labels, test_data, params, cat_features, n_splits=5):\n",
    "    ps = {'f1':0,\n",
    "          'param': [],\n",
    "          'best_model':None,\n",
    "    }\n",
    "    for prms in tqdm(list(ParameterGrid(params)), ascii=True, desc='Params Tuning:\\n'):\n",
    "        print('cat_serachParm 搜索最佳参数 .......',prms)\n",
    "        clf = cat_model(prms['loss_function'],prms['learning_rate'],prms['depth'],prms['l2_leaf_reg'],cat_features)             \n",
    "        f1 = cross_val(clf,train_data, train_labels, n_splits=5)\n",
    "        if acc>ps['f1']:\n",
    "            ps['f1'] = f1\n",
    "            ps['param'] = prms\n",
    "            ps['best_model'] = clf\n",
    "            print('f1: '+str(ps['f1']))\n",
    "            print('Params: '+str(ps['param']))\n",
    "    print('f1: '+str(ps['f1']))\n",
    "    print('Params: '+str(ps['param']))\n",
    "    return ps['best_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cat_serachParm 搜索最佳参数 ....... {'depth': [4, 5, 6, 7, 8], 'learning_rate': [0.03, 0.035, 0.04, 0.045, 0.05, 0.055, 0.06, 0.065], 'loss_function': ['Logloss', 'CrossEntropy'], 'l2_leaf_reg': array([1.00000000e-20, 3.16227766e-20, 1.00000000e-19])}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "          'depth': [4, 5, 6,7,8],\n",
    "          'learning_rate': [0.03, 0.035, 0.040, 0.045,0.05,0.055,0.06,0.065],\n",
    "          'loss_function':  ['Logloss'],\n",
    "          'l2_leaf_reg': [10],\n",
    "         }\n",
    "print('cat_serachParm 搜索最佳参数 .......',params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Params Tuning::   0%|          | 0/240 [00:00<?, ?it/s]cat_serachParm 搜索最佳参数 ....... {'depth': 4, 'l2_leaf_reg': 1e-20, 'learning_rate': 0.03, 'loss_function': 'Logloss'}\n",
      "Params Tuning::   0%|          | 0/240 [00:20<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-395-24f755c13c92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatboost_GridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-393-9e5e7e807881>\u001b[0m in \u001b[0;36mcatboost_GridSearchCV\u001b[0;34m(train_data, train_labels, test_data, params, cat_features, n_splits)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cat_serachParm 搜索最佳参数 .......'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'depth'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'l2_leaf_reg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-380-9696f864d87a>\u001b[0m in \u001b[0;36mcross_val\u001b[0;34m(model, train_data, train_labels, n_splits)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mf1_score_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/ml/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   4298\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_classification_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4300\u001b[0;31m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0m\u001b[1;32m   4301\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4302\u001b[0m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\n",
      "\u001b[0;32m/opt/miniconda3/envs/ml/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1803\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mlog_fixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_train_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1804\u001b[0;31m             self._train(\n\u001b[0m\u001b[1;32m   1805\u001b[0m                 \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m                 \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_sets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/ml/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1258\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1259\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model = catboost_GridSearchCV(train_data,train_labels,test_data,params,cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}